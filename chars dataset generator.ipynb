{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7adb57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from string import ascii_letters, digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b3469d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m DATA_ROOT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/SynthText\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m GT_PATH   \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_ROOT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# GT = Ground Truth\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading annotations...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m gt \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mloadmat(GT_PATH, struct_as_record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, squeeze_me\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"datasets/SynthText\"\n",
    "GT_PATH   = os.path.join(DATA_ROOT, \"gt.mat\") # GT = Ground Truth\n",
    "\n",
    "print(\"Loading annotations...\")\n",
    "gt = scipy.io.loadmat(GT_PATH, struct_as_record=False, squeeze_me=True)\n",
    "# GT is now a dict with keys: 'imnames', 'wordBB', 'charBB', 'txt'\n",
    "print(gt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b16d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(gt['imnames']) # should be 858750\n",
    "NUM_SAMPLES = 10000   \n",
    "\n",
    "# Pick NUM_SAMPLES unique image indices\n",
    "sampled_idxs = random.sample(range(num_images), NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09b9b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output directory\n",
    "OUTPUT_ROOT = \"datasets/step1_chars\"\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b82d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: saved 62000 crops, skipped 5 bad entries.\n",
      "\n",
      "=== Sample counts per class ===\n",
      "0: 1000\n",
      "1: 1000\n",
      "2: 1000\n",
      "3: 1000\n",
      "4: 1000\n",
      "5: 1000\n",
      "6: 1000\n",
      "7: 1000\n",
      "8: 1000\n",
      "9: 1000\n",
      "A: 1000\n",
      "B: 1000\n",
      "C: 1000\n",
      "D: 1000\n",
      "E: 1000\n",
      "F: 1000\n",
      "G: 1000\n",
      "H: 1000\n",
      "I: 1000\n",
      "J: 1000\n",
      "K: 1000\n",
      "L: 1000\n",
      "M: 1000\n",
      "N: 1000\n",
      "O: 1000\n",
      "P: 1000\n",
      "Q: 1000\n",
      "R: 1000\n",
      "S: 1000\n",
      "T: 1000\n",
      "U: 1000\n",
      "V: 1000\n",
      "W: 1000\n",
      "X: 1000\n",
      "Y: 1000\n",
      "Z: 1000\n",
      "a: 1000\n",
      "b: 1000\n",
      "c: 1000\n",
      "d: 1000\n",
      "e: 1000\n",
      "f: 1000\n",
      "g: 1000\n",
      "h: 1000\n",
      "i: 1000\n",
      "j: 1000\n",
      "k: 1000\n",
      "l: 1000\n",
      "m: 1000\n",
      "n: 1000\n",
      "o: 1000\n",
      "p: 1000\n",
      "q: 1000\n",
      "r: 1000\n",
      "s: 1000\n",
      "t: 1000\n",
      "u: 1000\n",
      "v: 1000\n",
      "w: 1000\n",
      "x: 1000\n",
      "y: 1000\n",
      "z: 1000\n",
      "\n",
      "Below minimum threshold:\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT             = \"datasets/SynthText\"\n",
    "GT_PATH               = os.path.join(DATA_ROOT, \"gt.mat\")\n",
    "OUTPUT_ROOT           = \"datasets/step1_chars\"\n",
    "MIN_SAMPLES_PER_CLASS = 1000 # Often bottlenecks on capital Z's for ascii chars\n",
    "MAX_SAMPLES_PER_CLASS = 1000\n",
    "random.seed(42)\n",
    "\n",
    "# Load SynthText annotations\n",
    "imnames = gt['imnames']\n",
    "charBB  = gt['charBB']\n",
    "txt     = gt['txt']\n",
    "\n",
    "# Shuffle indices\n",
    "indices = list(range(len(imnames)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Valid alphanumeric labels\n",
    "valid_labels = list(ascii_letters + digits)\n",
    "\n",
    "# Prepare output dirs & counters\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "counts = {lbl: 0 for lbl in valid_labels}\n",
    "for lbl in valid_labels:\n",
    "    os.makedirs(os.path.join(OUTPUT_ROOT, lbl), exist_ok=True)\n",
    "\n",
    "# Helpers\n",
    "def extract_chars(txt_entry):\n",
    "    \"\"\"\n",
    "    Function name: extract_chars\n",
    "    Description: Convert a raw text entry into a list of non-whitespace characters.\n",
    "    Parameters:\n",
    "        txt_entry (str or np.ndarray): Raw string or array of substrings from the SynthText annotations.\n",
    "    Return Value:\n",
    "        list[str]: Flattened list of individual characters, excluding any whitespace.\n",
    "    \"\"\"\n",
    "    if isinstance(txt_entry, str):\n",
    "        txt_str = txt_entry\n",
    "    elif isinstance(txt_entry, np.ndarray):\n",
    "        parts = []\n",
    "        for item in txt_entry.flatten().tolist():\n",
    "            if isinstance(item, str):\n",
    "                parts.append(item)\n",
    "            elif isinstance(item, np.ndarray):\n",
    "                try:\n",
    "                    parts.append(\"\".join(item.tolist()))\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                parts.append(str(item))\n",
    "        txt_str = \"\".join(parts)\n",
    "    else:\n",
    "        txt_str = str(txt_entry)\n",
    "    return [c for c in txt_str if not c.isspace()]\n",
    "\n",
    "def crop_char_safe(img, box):\n",
    "    \"\"\"\n",
    "    Function name: crop_char_safe\n",
    "    Description: Safely crop a rectangular patch from an RGB image given bounding‚Äêbox coordinates,\n",
    "                 clamping the crop to image boundaries.\n",
    "    Parameters:\n",
    "        img (np.ndarray): Source image in RGB format (HxWx3).\n",
    "        box (np.ndarray): Array of shape (2,4) giving the four corner coordinates [xs; ys] of the character box.\n",
    "    Return Value:\n",
    "        np.ndarray or None: Cropped image patch if valid, otherwise None if the box is degenerate or outside the image.\n",
    "    \"\"\"\n",
    "    xs, ys = box[0, :], box[1, :]\n",
    "    x1, x2 = int(xs.min()), int(xs.max())\n",
    "    y1, y2 = int(ys.min()), int(ys.max())\n",
    "    H, W = img.shape[:2]\n",
    "    x1, x2 = max(0, x1), min(W, x2)\n",
    "    y1, y2 = max(0, y1), min(H, y2)\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    return img[y1:y2, x1:x2]\n",
    "\n",
    "# Main loop\n",
    "saved, skipped = 0, 0\n",
    "for idx in indices:\n",
    "    if all(count >= MIN_SAMPLES_PER_CLASS for count in counts.values()):\n",
    "        break\n",
    "\n",
    "    name = imnames[idx]\n",
    "    img_path = os.path.join(DATA_ROOT, name)\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    if img_bgr is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB) #convert to RGB for consistency with Python libraries\n",
    "\n",
    "    boxes     = charBB[idx]\n",
    "    txt_entry = txt[idx]\n",
    "    chars     = extract_chars(txt_entry)\n",
    "    if boxes.shape[2] != len(chars):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(name))[0]\n",
    "    for j, ch in enumerate(chars):\n",
    "        if ch not in valid_labels or counts[ch] >= MAX_SAMPLES_PER_CLASS:\n",
    "            continue\n",
    "        patch = crop_char_safe(img_rgb, boxes[:, :, j])\n",
    "        if patch is None:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        patch = cv2.resize(patch, (32, 32), interpolation=cv2.INTER_AREA) #32 x 32 image resizing\n",
    "        out_dir = os.path.join(OUTPUT_ROOT, ch)\n",
    "        out_name = f\"{base}_{j}.png\"\n",
    "        cv2.imwrite(os.path.join(out_dir, out_name),\n",
    "                    cv2.cvtColor(patch, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        counts[ch] += 1\n",
    "        saved += 1\n",
    "\n",
    "print(f\"Done: saved {saved} crops, skipped {skipped} bad entries.\\n\")\n",
    "\n",
    "# Final distribution\n",
    "print(\"=== Sample counts per class ===\")\n",
    "for lbl in sorted(valid_labels):\n",
    "    print(f\"{lbl}: {counts[lbl]}\")\n",
    "print(\"\\nBelow minimum threshold:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    if cnt < MIN_SAMPLES_PER_CLASS:\n",
    "        print(f\"  {lbl}: {cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bad6f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : # images\n",
      "------------------------\n",
      "0        : 1000\n",
      "1        : 1000\n",
      "2        : 1000\n",
      "3        : 1000\n",
      "4        : 1000\n",
      "5        : 1000\n",
      "6        : 1000\n",
      "7        : 1000\n",
      "8        : 1000\n",
      "9        : 1000\n",
      "a        : 2000\n",
      "b        : 2000\n",
      "c        : 2000\n",
      "d        : 2000\n",
      "e        : 2000\n",
      "f        : 2000\n",
      "g        : 2000\n",
      "h        : 2000\n",
      "i        : 2000\n",
      "j        : 2000\n",
      "k        : 2000\n",
      "l        : 2000\n",
      "m        : 2000\n",
      "n        : 2000\n",
      "o        : 2000\n",
      "p        : 2000\n",
      "q        : 2000\n",
      "r        : 2000\n",
      "s        : 2000\n",
      "t        : 2000\n",
      "u        : 2000\n",
      "v        : 2000\n",
      "w        : 2000\n",
      "x        : 2000\n",
      "y        : 2000\n",
      "z        : 2000\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"datasets/step1_chars\")\n",
    "\n",
    "print(\"Character : # images\")\n",
    "print(\"-\" * 24)\n",
    "for char_dir in sorted(DATA_ROOT.iterdir()):\n",
    "    if not char_dir.is_dir():\n",
    "        continue\n",
    "    count = len(list(char_dir.glob(\"*.png\")))\n",
    "    print(f\"{char_dir.name:8s} : {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa475830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 36 labels, dropping 0 labels\n",
      "Rare labels: []\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"datasets/step1_chars\")\n",
    "# build a dict of label : count\n",
    "counts = {lbl: len(list((DATA_ROOT/lbl).glob(\"*.png\")))\n",
    "          for lbl in os.listdir(DATA_ROOT)\n",
    "          if (DATA_ROOT/lbl).is_dir()}\n",
    "\n",
    "# choose the cutoff\n",
    "MIN_COUNT = 200\n",
    "\n",
    "valid_labels = [lbl for lbl,c in counts.items() if c >= MIN_COUNT]\n",
    "rare_labels  = [lbl for lbl,c in counts.items() if c <  MIN_COUNT]\n",
    "\n",
    "print(f\"Keeping {len(valid_labels)} labels, dropping {len(rare_labels)} labels\")\n",
    "print(\"Rare labels:\", rare_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
