I developed a unified text detection and recognition pipeline in Python using PyTorch that follows the YOLO architecture to perform single-stage word localization and character classification directly on noisy natural images. The pipeline preprocesses the SynthText dataset 
by resizing inputs to 448 by 448 pixels and deriving anchor box priors via KMeans clustering on normalized ground truth bounding box dimensions. I implemented a custom YOLOBackbone that stacks ConvBlock modules with BatchNorm and LeakyReLU activations to extract 256 feature 
channels at 56 by 56 resolution and a YOLOHead that predicts per-grid-cell anchor offsets, objectness scores and class logits. The training strategy uses a hybrid loss that combines mean squared error for coordinate regression, generalized IoU loss for bounding box alignment, 
binary cross entropy for objectness with negative anchor sampling and a classification loss weighted to balance multiple objectives while optimizing with AdamW and a CosineAnnealing learning rate scheduler. I also trained a character-level CNN on cropped 32 by 32 samples and 
compared its accuracy to a Tesseract baseline, and evaluated end-to-end box IoU performance against the EAST detector using custom non maximum suppression post-processing. The entire system leverages torchvision transforms, DataLoader subsets and real-time data augmentation 
to produce quantitative IoU metrics and visual plots of ground truth versus predicted boxes that demonstrate consistent performance gains
